{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import Bio\n",
    "import statsmodels.api as sm\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all excelsheets as a dataframe and store it in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"C:/Users/marik/Downloads/Bioinfo_data_download/Bioinfo_data_extracted\"\n",
    "file_list = os.listdir(data_dir)\n",
    "\"\"\" raw_data={}\n",
    "for n in range(len(file_list)):\n",
    "    file_path = os.path.join(data_dir, file_list[n])\n",
    "    raw_data[file_list[n]] = pd.read_excel(file_path, header=0) \"\"\"\n",
    "raw_data ={os.path.splitext(filename)[0]: pd.read_excel(os.path.join(data_dir, filename), header=0) \n",
    "        for filename in file_list}\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing\n",
    "#print(raw_data.keys())\n",
    "print(raw_data.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adjust the key names to only exlucde TPP_ and .xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = {key[4:]: value for key, value in raw_data.items()} # remove 'TPP_' from the keys\n",
    "raw_data = {key[:-5]: value for key, value in raw_data.items()} # remove '.xlsx' from the keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing\n",
    "print(raw_data.keys())\n",
    "print(raw_data.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of column headers copied from excel sheet. For columns to keep headers where removed manually.\n",
    "\n",
    "The code iterates through every dataframe in the raw_data dictionary and for each dataframe adjusts the entries of the col_name list and saves them in drop_list, and then drops all columns based on this list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = ['norm_FC_TMT126_H.sapiens_HEK293_PP018224', 'norm_FC_TMT127L_H.sapiens_HEK293_PP018224', 'norm_FC_TMT127H_H.sapiens_HEK293_PP018224', \n",
    "            'norm_FC_TMT128L_H.sapiens_HEK293_PP018224', 'norm_FC_TMT128H_H.sapiens_HEK293_PP018224', 'norm_FC_TMT129L_H.sapiens_HEK293_PP018224', \n",
    "            'norm_FC_TMT129H_H.sapiens_HEK293_PP018224', 'norm_FC_TMT130L_H.sapiens_HEK293_PP018224', 'norm_FC_TMT130H_H.sapiens_HEK293_PP018224', \n",
    "            'norm_FC_TMT131L_H.sapiens_HEK293_PP018224', 'a_H.sapiens_HEK293_PP018224', 'b_H.sapiens_HEK293_PP018224', \n",
    "            'inflPoint_H.sapiens_HEK293_PP018224', 'slope_H.sapiens_HEK293_PP018224', 'plateau_H.sapiens_HEK293_PP018224', \n",
    "            'R_sq_H.sapiens_HEK293_PP018224', 'plot', 'protein_identified_in_H.sapiens_HEK293_PP018224', 'model_converged_H.sapiens_HEK293_PP018224', \n",
    "            'sufficient_data_for_fit_H.sapiens_HEK293_PP018224','numSpec_H.sapiens_HEK293_PP018224','plot_link']\n",
    "\n",
    "key_list = list(raw_data.keys())\n",
    "drop_list:list = []\n",
    "\n",
    "for n in range(len(key_list)):\n",
    "    for a in range (len(col_name)):\n",
    "        drop_list.append(re.sub('H.sapiens_HEK293_PP018224', str(key_list[n]), str(col_name[a])))\n",
    "        raw_data[key_list[n]] = raw_data[key_list[n]].drop(columns=drop_list, axis=1, errors = 'ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing\n",
    "print(raw_data.keys())\n",
    "print(raw_data.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new column for each dataframe in the dictionary and add the name of the sample (key name) to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw_data.keys())\n",
    "print(raw_data.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ERROR: this block seems to remove values from dictionary\n",
    "#new column with names of the files\n",
    "data = raw_data.copy()\n",
    "data_key = list (data.keys())\n",
    "for n in range(len(data_key)):\n",
    "    new_col = pd.Series(str(data_key[n]), index = data[data_key[n]].index)\n",
    "    if data[data_key[n]].columns[0] != 'Sample':\n",
    "        mod_df= data[data_key[n]].insert(loc=0, column = 'Sample', value = new_col)\n",
    "        data[data_key[n]] = mod_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing\n",
    "print(raw_data.keys())\n",
    "print(data.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_test = data[key_list[0]]\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create one big joined dataframe from the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_human = pd.concat(data.values(), axis = 0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
