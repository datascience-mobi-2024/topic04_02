{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import mdtraj as md\n",
    "import mdtraj.testing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<mdtraj.Trajectory with 1 frames, 1105 atoms, 143 residues, without unitcells>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marik\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\mdtraj\\formats\\pdb\\pdbfile.py:206: UserWarning: Unlikely unit cell vectors detected in PDB file likely resulting from a dummy CRYST1 record. Discarding unit cell vectors.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "t = md.load('./data/pdbs/AF-C0H3V2-F1.pdb')\n",
    "print(t)\n",
    "hbonds = md.baker_hubbard(t)\n",
    "for hbond in hbonds:\n",
    "    print(hbond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = lambda hbond: f\"{t.topology.atom(hbond[0])} -- {t.topology.atom(hbond[2])}\"\n",
    "\n",
    "for hbond in hbonds:\n",
    "    print(label(hbond))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VdW_interaction(path, pqr_files=None, output = None):\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import scipy\n",
    "    from scipy.spatial.distance import cdist\n",
    "    Donor_list = [('GLN', 'NE2', 'HE21'), ('GLN', 'NE2', 'HE22'), ('GLU', 'OE2', 'HE2'), ('ASP', 'OD2', 'HD2'), ('ASN', 'ND2', 'HD21'), ('ASN', 'ND2', 'HD22'),\n",
    "                    ('HIS', 'NE2', 'HE2'), ('HIS', 'ND1', 'HD2'), ('LYS', 'NZ', 'HZ1'), ('LYS', 'NZ', 'HZ2'), ('LYS', 'NZ', 'HZ3'), ('ARG', 'NE', 'HE'), \n",
    "                    ('ARG', 'NH1', 'HH11'), ('ARG', 'NH1', 'HH12'), ('ARG', 'NH2', 'HH21'), ('ARG', 'NH2', 'HH22'), ('SER', 'OG', 'HG'), ('THR', 'OG1', 'HG1'), \n",
    "                    ('TRP', 'NE1', 'HE1'), ('TYR', 'OH', 'HH')]\n",
    "    Acceptor_list = [('GLN', 'OE1'), ('ASP', 'OD1'), ('ASP', 'OD2'), ('ASN', 'OD1')]\n",
    "    \n",
    "    if pqr_files is None:\n",
    "        pqr_files = [f for f in os.listdir(path) if f.endswith('.pdb')]\n",
    "    if isinstance(pqr_files, str):\n",
    "        pqr_files = [pqr_files]\n",
    "    for pqr_file in pqr_files:\n",
    "        with open(os.path.join(path, 'C0H3Z2.pqr')) as f:\n",
    "            HB_dic = {}\n",
    "            Donor_array = np.empty((0, 4))\n",
    "            H_array = np.empty((0, 4))\n",
    "            Acceptor_array = np.empty((0, 4))\n",
    "            aa_cache = []\n",
    "            atom_cache = []\n",
    "            test_count = 0\n",
    "            for line in f:\n",
    "                if line.startswith('ATOM'):\n",
    "                    if not aa_cache:\n",
    "                        aa_cache.append(line.split()[3])\n",
    "                        aa_cache.append(line.split()[4])\n",
    "                        atom_cache.append(line)\n",
    "                    elif aa_cache[1] == line.split()[4]:\n",
    "                        atom_cache.append(line)\n",
    "                    elif aa_cache[1] != line.split()[4]:\n",
    "                        test_count += 1             \n",
    "                        for n in range(len(Donor_list)):\n",
    "                            if aa_cache[0] == Donor_list[n][0]:\n",
    "                                for i in range(len(atom_cache)):\n",
    "                                    if Donor_list[n][1] == atom_cache[i].split()[2]:\n",
    "                                        if ('GLU' == aa_cache[0]) and 'OE2' in atom_cache[i].split()[2]:\n",
    "                                            if any('HE2' in string for string in atom_cache):\n",
    "                                                line_array = np.array([[atom_cache[i].split()[1], atom_cache[i].split()[5], atom_cache[i].split()[6], atom_cache[i].split()[7]]])\n",
    "                                                line_array = line_array.astype('float64')\n",
    "                                                Donor_array = np.append(Donor_array, line_array, axis=0) \n",
    "                                        elif ('ASP' == aa_cache[0]) and 'OD2' in atom_cache[i].split()[2]:\n",
    "                                            if any('HD2' in string for string in atom_cache):\n",
    "                                                line_array = np.array([[atom_cache[i].split()[1], atom_cache[i].split()[5], atom_cache[i].split()[6], atom_cache[i].split()[7]]])\n",
    "                                                line_array = line_array.astype('float64')\n",
    "                                                Donor_array = np.append(Donor_array, line_array, axis=0)                                             \n",
    "                                        elif ('HIS' == aa_cache[0]) and 'ND1' in atom_cache[i].split()[2]:\n",
    "                                            if any ('HD1' in string for string in atom_cache):\n",
    "                                                line_array = np.array([[atom_cache[i].split()[1], atom_cache[i].split()[5], atom_cache[i].split()[6], atom_cache[i].split()[7]]])\n",
    "                                                line_array = line_array.astype('float64')\n",
    "                                                Donor_array = np.append(Donor_array, line_array, axis=0)\n",
    "                                        elif ('HIS' == aa_cache[0]) and 'NE2' in atom_cache[i].split()[2]:\n",
    "                                            if any('HE2' in string for string in atom_cache):\n",
    "                                                line_array = np.array([[atom_cache[i].split()[1], atom_cache[i].split()[5], atom_cache[i].split()[6], atom_cache[i].split()[7]]])\n",
    "                                                line_array = line_array.astype('float64')\n",
    "                                                Donor_array = np.append(Donor_array, line_array, axis=0)\n",
    "                                        else: \n",
    "                                            line_array = np.array([[atom_cache[i].split()[1], atom_cache[i].split()[5], atom_cache[i].split()[6], atom_cache[i].split()[7]]])\n",
    "                                            line_array = line_array.astype('float64')\n",
    "                                            Donor_array = np.append(Donor_array, line_array, axis=0)         \n",
    "                                    elif Donor_list[n][2] == atom_cache[i].split()[2]:\n",
    "                                        line_array = np.array([[atom_cache[i].split()[1], atom_cache[i].split()[5], atom_cache[i].split()[6], atom_cache[i].split()[7]]])\n",
    "                                        line_array = line_array.astype('float64')\n",
    "                                        H_array = np.append(H_array, line_array, axis=0)\n",
    "                        for n in range(len(Acceptor_list)):\n",
    "                            if aa_cache[0] == Acceptor_list[n][0]:\n",
    "                                for i in range(len(atom_cache)):\n",
    "                                    if Acceptor_list[n][1] == atom_cache[i].split()[2]:\n",
    "                                        if ('GLU' == aa_cache[0]) and 'OE2' in atom_cache[i].split()[2]:\n",
    "                                            if any('HE2' not in string for string in atom_cache):\n",
    "                                                line_array = np.array([[atom_cache[i].split()[1], atom_cache[i].split()[5], atom_cache[i].split()[6], atom_cache[i].split()[7]]])\n",
    "                                                line_array = line_array.astype('float64')\n",
    "                                                Acceptor_array = np.append(Acceptor_array, line_array, axis=0)\n",
    "                                        elif ('ASP' == aa_cache[0]) and 'OD' in atom_cache[i].split()[2]:\n",
    "                                            if any('HD' not in string for string in atom_cache):\n",
    "                                                line_array = np.array([[atom_cache[i].split()[1], atom_cache[i].split()[5], atom_cache[i].split()[6], atom_cache[i].split()[7]]])\n",
    "                                                line_array = line_array.astype('float64')\n",
    "                                                Acceptor_array = np.append(Acceptor_array, line_array, axis=0)\n",
    "                                        else: \n",
    "                                            line_array = np.array([[atom_cache[i].split()[1], atom_cache[i].split()[5], atom_cache[i].split()[6], atom_cache[i].split()[7]]])\n",
    "                                            line_array = line_array.astype('float64')\n",
    "                                            Acceptor_array = np.append(Acceptor_array, line_array, axis=0) \n",
    "            from helper_function import distance\n",
    "            from helper_function import angle_calc\n",
    "            angle = angle_calc(Donor_array, H_array, Acceptor_array)\n",
    "            HB_dic[str(pqr_file).split('.')[1]] = angle\n",
    "    return HB_dic\n",
    "                                            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance (array1, array2, cutoff = None, remove_nan=True):\n",
    "    from scipy.spatial.distance import cdist\n",
    "    import numpy as np\n",
    "    distance = cdist(array1[:,1:], array2[:,1:], metric='euclidean') #calculate distance\n",
    "    distance = np.concatenate((np.array([array1[:,0]]).T, distance), axis=1) #add atom number from  array1\n",
    "    distance = np.concatenate(((np.insert(np.array([array2[:,0]]), 0, None).reshape(-1,1)).T, distance), axis=0) #add atom number from array1\n",
    "    if cutoff is not None:\n",
    "        distance[1:, 1:][distance[1:, 1:] >= cutoff] = np.nan #set distance > cutoff to nan\n",
    "        \n",
    "    if remove_nan == False:\n",
    "        return distance\n",
    "    elif remove_nan == True:\n",
    "        rows_with_nan = np.insert(np.array([np.all(np.isnan(distance[1:, 1:]), axis=1)]),0, None)\n",
    "        rows_with_nan = np.insert(np.array([np.all(np.isnan(distance[1:, 1:]), axis=1)]),0, None) #find rows with all nan values\n",
    "        cols_with_nan = np.insert(np.array([np.all(np.isnan(distance[1:, 1:]), axis=0)]),0, None) #find columns with all nan values\n",
    "        distance = distance[~rows_with_nan, :] #delete rows with all nan values\n",
    "        distance = distance[:, ~cols_with_nan] #delete columns with all nan values\n",
    "        distance[:,0] = distance[:,0].astype('int')\n",
    "        return distance\n",
    "    else:\n",
    "        raise ValueError('remove_nan must be either True or False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 12, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marik\\AppData\\Local\\Temp\\ipykernel_1868\\3944719170.py:18: RuntimeWarning: invalid value encountered in cast\n",
      "  distance[:,0] = distance[:,0].astype('int')\n",
      "C:\\Users\\marik\\AppData\\Local\\Temp\\ipykernel_1868\\3632117180.py:12: RuntimeWarning: invalid value encountered in arccos\n",
      "  theta = np.arccos((d_DH[n,1,1]**2 + d_HA[n,1:]**2 - d_DA[1:,1:][n,:]**2)/(2*d_DH[n,1,1]*d_HA[1:,1:][n,:]))\n"
     ]
    }
   ],
   "source": [
    "def angle_calc(Donor_array, H_array, Acceptor_array):\n",
    "    d_DH = np.full((0,2,2), fill_value = np.nan)\n",
    "    for n in range(len(Donor_array)):\n",
    "        DH_temp = distance(np.array([Donor_array[n,:]]), np.array([H_array[n,:]]))\n",
    "        d_DH = np.concatenate((d_DH, DH_temp.reshape((1,) + DH_temp.shape)), axis=0)\n",
    "    d_HA = distance(Donor_array, Acceptor_array, remove_nan=False, cutoff = 3.5)\n",
    "    \n",
    "    d_DA = distance(Donor_array, Acceptor_array, remove_nan=False)\n",
    "    angle = np.full((d_DA.shape[0], d_DA.shape[1]), fill_value = np.nan)\n",
    "    angle[0,:] = d_DA[0,:].T\n",
    "    for n in range(d_DH.shape[0]):\n",
    "            theta = np.arccos((d_DH[n,1,1]**2 + d_HA[n,1:]**2 - d_DA[1:,1:][n,:]**2)/(2*d_DH[n,1,1]*d_HA[1:,1:][n,:]))\n",
    "            theta[(theta < 100* np.pi/180) | (theta > np.pi)] = np.nan\n",
    "            angle[n,0] = d_DA[n,0]\n",
    "            angle[1:,1:][n,:] = theta \n",
    "    H_id = np.full((angle.shape[0], angle.shape[1]), fill_value = np.nan)\n",
    "    H_id[1:,0] = d_DH[:,1,0]\n",
    "    angle = np.dstack((angle, H_id))\n",
    "    return angle\n",
    "\n",
    "\n",
    "angle = angle_calc(Donor_array, H_array, Acceptor_array)\n",
    "print(angle.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [  28.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [  28.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [  28.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [  67.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 136.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 137.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 137.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 138.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 138.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 208.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 220.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 252.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 253.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 253.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 254.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 254.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 276.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 277.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 277.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 278.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 278.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 300.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 301.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 301.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 302.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 302.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 339.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 339.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 339.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 390.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 408.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 408.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 431.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 431.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 484.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 512.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 541.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 541.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 541.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 562.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 563.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 563.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 564.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 564.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 596.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 617.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 618.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 618.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 619.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 619.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 683.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 683.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 755.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 809.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 867.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 993.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 994.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 994.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 995.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [ 995.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [1055.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [1055.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      " [1055.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan]]\n"
     ]
    }
   ],
   "source": [
    "print(angle[:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63, 63)\n",
      "(64, 12)\n",
      "(64, 12)\n"
     ]
    }
   ],
   "source": [
    "d_DH = distance(Donor_array, H_array, cutoff =2.5 )\n",
    "d_HA = distance(H_array, Acceptor_array)\n",
    "d_DA = distance(Donor_array, Acceptor_array)\n",
    "\n",
    "print(d_DH.shape)\n",
    "print(d_HA.shape)\n",
    "print(d_DA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1']\n",
      "yes\n"
     ]
    }
   ],
   "source": [
    "string = 'ATOM     12  HB3 MET     1     -20.987   0.463   6.535  0.0000 0.0000'\n",
    "string2 ='ATOM      5  O   MET     1     -18.415  -1.135   7.336 -0.5500 1.4000'\n",
    "list2 = [string.split()[4]]\n",
    "print(list2)\n",
    "\n",
    "if list2[0] == string2.split()[4]:\n",
    "    print('yes')\n",
    "else:\n",
    "    print('no')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
