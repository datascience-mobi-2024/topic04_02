{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tobia\\AppData\\Local\\Temp\\ipykernel_364\\565201268.py:10: DtypeWarning: Columns (8,21,22,23,25,26,27,28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('./data/prokaryotes_323columns.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data - MSE: 71.32297620078292, R2: 0.7095110515520897\n",
      "PCA Data - MSE: 67.9436125172314, R2: 0.7232747481215434\n",
      "PCA improved the model's performance.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming df is your dataframe and 'target' is the column name of the target variable\n",
    "df = pd.read_csv('./data/prokaryotes_323columns.csv')\n",
    "droplist = [0,1,2,3,4,5,6,7,8,10,11,12,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,33,38,43]\n",
    "col = df.columns\n",
    "dropl2 = []\n",
    "\"\"\" for n in col:\n",
    "    if len(n) == 2:\n",
    "        dropl2.append(n) \"\"\"\n",
    "df = df.drop(df.columns[droplist], axis=1)\n",
    "df = df.drop(dropl2, axis=1)\n",
    "df['saltperaa'] = df['A_Salty'] / df['Length']\n",
    "df = df.drop(['helixind','helixseq'],axis = 1)\n",
    "df = df.reset_index(drop=True)\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df = df.fillna(0)\n",
    "X = df.drop('meltPoint', axis=1)\n",
    "y = df['meltPoint']\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train and evaluate the Gradient Boosting Regressor on the original data\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "y_pred = gbr.predict(X_test)\n",
    "\n",
    "# Calculate performance metrics\n",
    "mse_original = mean_squared_error(y_test, y_pred)\n",
    "r2_original = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Original Data - MSE: {mse_original}, R2: {r2_original}\")\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=0.95)  # Retain 95% of the variance\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Split PCA data into training and testing sets\n",
    "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train and evaluate the Gradient Boosting Regressor on the PCA-transformed data\n",
    "gbr_pca = GradientBoostingRegressor()\n",
    "gbr_pca.fit(X_train_pca, y_train_pca)\n",
    "y_pred_pca = gbr_pca.predict(X_test_pca)\n",
    "\n",
    "# Calculate performance metrics\n",
    "mse_pca = mean_squared_error(y_test_pca, y_pred_pca)\n",
    "r2_pca = r2_score(y_test_pca, y_pred_pca)\n",
    "\n",
    "print(f\"PCA Data - MSE: {mse_pca}, R2: {r2_pca}\")\n",
    "\n",
    "# Compare results\n",
    "if mse_pca < mse_original:\n",
    "    print(\"PCA improved the model's performance.\")\n",
    "else:\n",
    "    print(\"PCA did not improve the model's performance.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tobia\\AppData\\Local\\Temp\\ipykernel_17040\\1450467610.py:12: DtypeWarning: Columns (8,21,22,23,25,26,27,28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('./data/prokaryotes_323columns.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.09916655057071823, 'max_depth': 5, 'min_samples_leaf': 3, 'min_samples_split': 9, 'n_estimators': 166, 'subsample': 0.9202230023486418}\n",
      "Tuned PCA Data - MSE: 66.65524061102938, R2: 0.7285221146810776\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "\n",
    "# Assuming df is your dataframe and 'target' is the column name of the target variable\n",
    "df = pd.read_csv('./data/prokaryotes_323columns.csv')\n",
    "droplist = [0,1,2,3,4,5,6,7,8,10,11,12,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,33,38,43]\n",
    "col = df.columns\n",
    "dropl2 = []\n",
    "\"\"\" for n in col:\n",
    "    if len(n) == 2:\n",
    "        dropl2.append(n) \"\"\"\n",
    "df = df.drop(df.columns[droplist], axis=1)\n",
    "df = df.drop(dropl2, axis=1)\n",
    "df['saltperaa'] = df['A_Salty'] / df['Length']\n",
    "df = df.drop(['helixind','helixseq'],axis = 1)\n",
    "df = df.reset_index(drop=True)\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df = df.fillna(0)\n",
    "X = df.drop('meltPoint', axis=1)\n",
    "y = df['meltPoint']\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=0.95)  # Retain 95% of the variance\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Split PCA data into training and testing sets\n",
    "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the parameter distribution\n",
    "param_dist = {\n",
    "    'n_estimators': randint(50, 300),\n",
    "    'learning_rate': uniform(0.01, 0.2),\n",
    "    'max_depth': randint(3, 6),\n",
    "    'min_samples_split': randint(2, 11),\n",
    "    'min_samples_leaf': randint(1, 5),\n",
    "    'subsample': uniform(0.8, 0.2)\n",
    "}\n",
    "\n",
    "# Initialize the Gradient Boosting Regressor\n",
    "gbr = GradientBoostingRegressor()\n",
    "\n",
    "# Initialize RandomizedSearchCV with 5-fold cross-validation\n",
    "random_search = RandomizedSearchCV(estimator=gbr, param_distributions=param_dist, n_iter=2, cv=5, n_jobs=1, random_state=42, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the random search to the data\n",
    "random_search.fit(X_train_pca, y_train_pca)\n",
    "\n",
    "# Get the best parameters and the best model\n",
    "best_params = random_search.best_params_\n",
    "best_gbr = random_search.best_estimator_\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "y_pred_pca_best = best_gbr.predict(X_test_pca)\n",
    "mse_pca_best = mean_squared_error(y_test_pca, y_pred_pca_best)\n",
    "r2_pca_best = r2_score(y_test_pca, y_pred_pca_best)\n",
    "\n",
    "print(f\"Tuned PCA Data - MSE: {mse_pca_best}, R2: {r2_pca_best}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
