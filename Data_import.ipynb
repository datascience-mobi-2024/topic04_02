{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import Bio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data from computer\n",
    "path: str = './data/' #folder where files are stored\n",
    "species: pd.DataFrame = pd.read_csv(os.path.join(path, \"cross-species.csv\"), dtype=str)   # imports file from the folder as species, based on name\n",
    "identifiers: pd.DataFrame = pd.read_csv(os.path.join(path, \"identifiers.tsv\"), sep='\\t', dtype=str) # imports 3rd file from the folder, based on name\n",
    "\n",
    "#import fasta file with biopython (Bio)\n",
    "from Bio import SeqIO\n",
    "fasta_id = []\n",
    "fasta_seq = []\n",
    "with open(os.path.join(path, \"identifiers.fasta\"), 'r') as handle:\n",
    "    for record in SeqIO.parse(handle, \"fasta\"): \n",
    "        fasta_id.append(record.id) \n",
    "        fasta_seq.append(str(record.seq))\n",
    "# Create df prot_seq which includes proper ID and sequences\n",
    "fasta_id_df = pd.DataFrame([item.split('|') for item in fasta_id], columns=['0', 'From','ID']) # creates a df by splitting fasta_id list into 3 columns\n",
    "fasta_id_EntryName:list = fasta_id_df['ID'] # creates a list with the Entry Names from the split df\n",
    "prot_seq = pd.DataFrame(list(zip(fasta_id_EntryName, fasta_seq)), columns = [\"ID\", \"Sequence\"]) # creates a df by combining the Entry Names and the Sequences\n",
    "\n",
    "# merge dataframes based on Entry Name (df.identifiers) andID (df.prot_seq), if they are similar add the sequence to identifiers, if not add NaN\n",
    "identifiers_seq = identifiers.merge(prot_seq, how='left', left_on='Entry Name', right_on='ID')[identifiers.columns.tolist() + ['Sequence']] # merges identifiers and prot_seq on Entry Name and ID\n",
    "#species.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1          TMT126\n",
       "2          TMT126\n",
       "3          TMT126\n",
       "5          TMT126\n",
       "7          TMT126\n",
       "            ...  \n",
       "1114705       NaN\n",
       "1114706       NaN\n",
       "1114707       NaN\n",
       "1114708       NaN\n",
       "1114709       NaN\n",
       "Name: channel, Length: 985230, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "species_clean = species.dropna(subset = [\"meltPoint\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
