{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tobia\\AppData\\Local\\Temp\\ipykernel_3628\\867054028.py:3: DtypeWarning: Columns (6,19,20,21,23,24,25,26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  prokaryotes = pd.read_csv(os.path.join(path, 'prokaryotes_348columns.csv'))\n"
     ]
    }
   ],
   "source": [
    "#Data preprocessing\n",
    "path = './data'\n",
    "prokaryotes = pd.read_csv(os.path.join(path, 'prokaryotes_348columns.csv'))\n",
    "droplist = [0,1,2,3,4,5,6,8,9,10,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,35,36,37,40,41,42,45,282,283,284,285,286,287,288,289,290,291,292,293,294,300,301,302,303,304,305,306,327]\n",
    "prokaryotes = prokaryotes.drop(prokaryotes.columns[droplist], axis=1)\n",
    "prokaryotes.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "prokaryotes = prokaryotes.fillna(0)\n",
    "prokaryotes = prokaryotes.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "295"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prokaryotes.columns.get_loc('HydrophobicAA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA Data - MSE: 63.7160764535022, R2: 0.7413429927613763\n"
     ]
    }
   ],
   "source": [
    "# Splitting data into X (features) and y (target)\n",
    "X = prokaryotes.drop('meltPoint', axis=1)\n",
    "y = prokaryotes['meltPoint']\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "pca = PCA(n_components=25)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(X_pca, y, test_size=0.2, random_state=1)\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train_pca, y_train_pca)\n",
    "y_pred_pca = gbr.predict(X_test_pca)\n",
    "mse_pca = mean_squared_error(y_test_pca, y_pred_pca)\n",
    "r2_pca = r2_score(y_test_pca, y_pred_pca)\n",
    "print(f\"PCA Data - MSE: {mse_pca}, R2: {r2_pca}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasparse(faspath):\n",
    "    helixl = []\n",
    "    sheetl = []\n",
    "    data = np.loadtxt(faspath, dtype={'names': ('index', 'col1', 'col2', 'val1', 'val2', 'val3'),'formats': ('i4', 'S1', 'S1', 'f4', 'f4', 'f4')})\n",
    "    indiceshelix = data['index'][data['col2'] == b'H']\n",
    "    indicessheet = data['index'][data['col2'] == b'E']\n",
    "    helix = np.split(indiceshelix, np.where(np.diff(indiceshelix) != 1)[0]+1)\n",
    "    sheet = np.split(indicessheet, np.where(np.diff(indicessheet) != 1)[0]+1)\n",
    "    return [helix, sheet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPARC: \"Sequence-based Protein Attribute-deRived Melt Point Calculator\"\n",
    "def SPARC(data:str, name, datapath, directoryS4):\n",
    "    \"\"\"\n",
    "    data: string, protein sequence\n",
    "    name: arbitrary name for the protein\n",
    "    datapath: string, path to data directory, only \"/\" allowed\n",
    "    directoryS4: string, compltete path to directory of S4pred, only \"/\" allowed\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import os\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.decomposition import PCA\n",
    "    from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "    from sklearn.metrics import mean_squared_error, r2_score\n",
    "    features = pd.Series(np.zeros(prokaryotes.shape[1]-1))\n",
    "    features.index = prokaryotes.drop(columns='meltPoint').columns\n",
    "    with open(os.path.join(datapath,f'{name}.fasta'), \"w\") as fasta_file:\n",
    "        fasta_file.write(f\">{name}\\n{data}\\n\")\n",
    "    os.chdir(directoryS4)\n",
    "    fastapath = os.path.join(datapath,f'{name}.fasta')\n",
    "    faspath = os.path.join(datapath,f'{name}.fas')\n",
    "    os.system(f'python3 run_model.py \"{fastapath}\" > \"{faspath}\"')\n",
    "    os.chdir('../../')\n",
    "    Protlen = len(data)\n",
    "    features.iloc[0] = Protlen\n",
    "    HelixSparc = fasparse(faspath)[0]\n",
    "    SheetSparc = fasparse(faspath)[1]\n",
    "    features.iloc[1] = len(HelixSparc)  #counts\n",
    "    features.iloc[2] = len(SheetSparc)\n",
    "    helixind = np.concatenate(HelixSparc)\n",
    "    helixseq = np.array(list(data))[list(helixind)]\n",
    "    sheetind = np.concatenate(SheetSparc)\n",
    "    sheetseq = np.array(list(data))[list(sheetind)]\n",
    "    features.iloc[3] = len(helixind) / Protlen #percs\n",
    "    features.iloc[4] = len(sheetind) / Protlen\n",
    "    features.iloc[5] = np.mean(np.array([len(arr) for arr in HelixSparc])) #avg lengths\n",
    "    features.iloc[6] = np.mean(np.array([len(arr) for arr in SheetSparc]))\n",
    "    features.iloc[7] = features.iloc[3] + features.iloc[4]\n",
    "    aapairs = features.index[8:87]\n",
    "    for aa in aapairs:\n",
    "        features[aa] = (data.count(aa[0]) + data.count(aa[1])) / Protlen\n",
    "    for acid in ['A', 'V', 'I', 'L', 'M', 'F', 'W','N', 'Q', 'S', 'T', 'Y','D', 'E','R', 'H', 'K', 'C', 'P', 'G' ]:\n",
    "        features[f'{acid}helix'] = helixseq.tolist().count(acid) / len(helixseq)\n",
    "        features[f'{acid}sheet'] = sheetseq.tolist().count(acid) / len(sheetseq)\n",
    "        features[acid] = data.count(acid) / Protlen\n",
    "    motifs = [motif[:2] for motif in np.array(features.iloc[107:243].index)]\n",
    "    for motif in motifs:\n",
    "        features[f'{motif}motif'] = data.count(motif) / Protlen\n",
    "    features['EALRmotif'] = data.count('EALR') / Protlen\n",
    "    features['LEALmotif'] = data.count('LEAL') / Protlen\n",
    "    features['HydrophobicAA'] = features['A'] + features['V'] + features['I'] + features['L'] + features['M'] + features['F'] + features['W']\n",
    "    features['ChargedAA'] = features['R'] + features['H'] + features['K'] + features['D'] + features['E']\n",
    "    features['PolarAA'] = features['N'] + features['Q'] + features['S'] + features['T'] + features['Y']\n",
    "    featuresdf = pd.DataFrame(features).T\n",
    "    features_scaled = scaler.transform(featuresdf)\n",
    "    features_pca = pca.transform(features_scaled)\n",
    "    prediction = gbr.predict(features_pca)\n",
    "    \n",
    "    return [prediction,features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "features2 = pd.Series(np. zeros(prokaryotes.shape[1]-1))\n",
    "features2.index = prokaryotes.drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "prt420 = 'MKMTSRKLSDILKQRLQHENRSFLFDREKDTLRVEDQTTKKGITLDLPPIIAKWELKKDEAIDEIVYYVSEAMTAMEGKAQEMTGKETRIYPVIRSTSFPDKSSEDIPLIYDDHTAETRIYYALDLGKTYRLIDQRMLEKENWTKERIRETAAFNLRSLPTVVKEDTVAGNYFYFFRANDGYDASRILNEAILNEYKQHAEGELAISVPHQDVLILADIRNESGYDILGQMSMSFFAGGTVPITALSFLYNEGKLEPVFILAKSRPKKD'\n",
    "sparctest = 'ARVCNMPREQDERVRCYNMKLPRWQASDPOILLINCVRTQWTILLPCVFGDQVY'\n",
    "O = SPARC(prt420,'sparctest',r'C:/Users/tobia/OneDrive/Documents/Uni/FS 4/Bioinfo Projekt/topic04_02/data/fastas',r'C:/Users/tobia/OneDrive/Documents/Uni/FS 4/Bioinfo Projekt/topic04_02/data/s4pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([46.93326437])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "O[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "Odf = pd.DataFrame(O).T\n",
    "Odf_scaled = scaler.transform(Odf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
